# -*- coding: utf-8 -*-
"""tata_genAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DJCY6WyP3ESPgwy5sNFhgCaPdWjpbJrF
"""

import pandas as pd
import matplotlib as mtpl
import sklearn as scil

from google.colab import files
uploaded = files.upload()

data = pd.read_csv("Delinquency_prediction_dataset.csv")
data.head()

data.describe()

print("Records:", data.shape[0])
print("Variables:", data.shape[1])
print(data.dtypes)
print("Missing values:\n", data.isnull().sum())
print("Duplicates:", data.duplicated().sum())

import matplotlib.pyplot as plt
import seaborn as sns

missing_values_to_plot = data[['Income', 'Credit_Score', 'Loan_Balance']].isnull().sum()

plt.figure(figsize=(8, 5))
sns.barplot(x=missing_values_to_plot.index, y=missing_values_to_plot.values)
plt.title('Count of Missing Values per Column')
plt.ylabel('Number of Missing Values')
plt.xlabel('Columns')
plt.show()

print("Missing values:\n", data.isnull().sum())
print("\nColumns with missing values:")
for col in data.columns:
  if data[col].isnull().sum() > 0:
    print(col)

import pandas as pd

# Create a table summarizing the missing data issues and handling methods
missing_data_summary = pd.DataFrame({
    'Column': ['Income', 'Credit_Score', 'Loan_Balance'],
    'Handling Method': ['Mean Imputation', 'Mean Imputation', 'Median Imputation'],
    'Justification': [
        'Preserves the overall mean for a numerical variable assuming normal distribution.',
        'Simple and common approach for a numerical variable with few missing values.',
        'More robust to outliers for a potentially skewed numerical variable.'
    ]
})

display(missing_data_summary)

"""Here is a summary of the missing data issues and the proposed handling methods:"""

display(missing_data_summary)

"""Here is a summary of the missing data issues and the proposed handling methods:"""

import pandas as pd
import numpy as np

# Imputation Strategy 1: Impute 'Income' with the mean, assuming a normal distribution.
# Justification: The mean is a good imputation strategy for numerical data that is approximately normally distributed, as it preserves the overall mean of the dataset.
income_mean = data['Income'].mean()
data['Income'].fillna(income_mean, inplace=True)

# Imputation Strategy 2: Impute 'Credit_Score' with the mean.
# Justification: Credit score is a numerical variable, and imputing with the mean is a common and simple approach when the number of missing values is small.
credit_score_mean = data['Credit_Score'].mean()
data['Credit_Score'].fillna(credit_score_mean, inplace=True)

# Imputation Strategy 3: Impute 'Loan_Balance' with the median.
# Justification: Loan balance might be skewed, and the median is more robust to outliers than the mean.
loan_balance_median = data['Loan_Balance'].median()
data['Loan_Balance'].fillna(loan_balance_median, inplace=True)

# Create a table summarizing the missing data issues and handling methods
missing_data_summary = pd.DataFrame({
    'Column': ['Income', 'Credit_Score', 'Loan_Balance'],
    'Handling Method': ['Mean Imputation', 'Mean Imputation', 'Median Imputation'],
    'Justification': [
        'Preserves the overall mean for a numerical variable assuming normal distribution.',
        'Simple and common approach for a numerical variable with few missing values.',
        'More robust to outliers for a potentially skewed numerical variable.'
    ]
})

print("Missing values after imputation:\n", data.isnull().sum())

from sklearn.preprocessing import StandardScaler

# Identify numerical columns (excluding the target variable and Customer_ID)
numerical_cols = data.select_dtypes(include=np.number).columns.tolist()
# Assuming 'Delinquent_Account' is the target variable and 'Customer_ID' is an identifier
if 'Delinquent_Account' in numerical_cols:
    numerical_cols.remove('Delinquent_Account')
if 'Customer_ID' in numerical_cols:
    numerical_cols.remove('Customer_ID')

# Initialize the StandardScaler
scaler = StandardScaler()

# Apply scaling to the numerical columns
data[numerical_cols] = scaler.fit_transform(data[numerical_cols])

print("Numerical features scaled.")
display(data.head())



# Select only the numerical columns excluding 'Customer_ID'
numerical_cols = data.select_dtypes(include=np.number).columns.tolist()
if 'Customer_ID' in numerical_cols:
    numerical_cols.remove('Customer_ID')
numerical_data = data[numerical_cols]

# Calculate the correlation matrix
correlation_matrix = numerical_data.corr()

# Create a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Features')
plt.show()

"""# Task
Analyze the provided dataset to identify correlations between numerical features and highlight any unexpected anomalies. Summarize the key correlations and describe the anomalies found.

## Calculate and visualize correlations

### Subtask:
Compute the correlation matrix for the numerical features and visualize it using a heatmap to understand the relationships between variables.

**Reasoning**:
Compute and visualize the correlation matrix for the numerical features.

**Reasoning**:
The 'Customer_ID' column was not dropped successfully in the previous attempt because it was not present in the numerical data subset. The 'Customer_ID' column is of object type, not numerical. I need to select numerical columns excluding 'Customer_ID' in the first step itself before calculating the correlation matrix.

## Summarize key correlations

### Subtask:
Based on the correlation heatmap, identify and summarize the notable positive and negative correlations between variables.

**Reasoning**:
Analyze the correlation matrix to identify and summarize the notable positive, negative, and weak correlations.
"""

# Reload the data as the variable 'data' was not found in the previous session
data = pd.read_csv("Delinquency_prediction_dataset.csv")

# Select numerical columns
numerical_cols = data.select_dtypes(include=np.number).columns.tolist()
if 'Customer_ID' in numerical_cols:
    numerical_cols.remove('Customer_ID')
if 'Delinquent_Account' in numerical_cols:
    numerical_cols.remove('Delinquent_Account')

# Iterate and plot box plots
for col in numerical_cols:
    plt.figure(figsize=(8, 5))
    sns.boxplot(y=data[col])
    plt.title(f'Box Plot of {col}')
    plt.ylabel(col)
    plt.show()

# Select numerical columns
numerical_cols = data.select_dtypes(include=np.number).columns.tolist()
if 'Customer_ID' in numerical_cols:
    numerical_cols.remove('Customer_ID')
if 'Delinquent_Account' in numerical_cols:
    numerical_cols.remove('Delinquent_Account')

# Iterate and plot box plots
for col in numerical_cols:
    plt.figure(figsize=(8, 5))
    sns.boxplot(y=data[col])
    plt.title(f'Box Plot of {col}')
    plt.ylabel(col)
    plt.show()

"""## Identify potential anomalies

### Subtask:
Explore the distributions of key numerical variables using plots like box plots or histograms to visually identify potential outliers or unusual patterns that might represent anomalies.

**Reasoning**:
Select numerical columns, iterate through them, and create box plots for each to visualize distributions and identify outliers, as per the instructions.

**Reasoning**:
The previous command failed because the dataframe `data` was not defined in the current session. Need to reload the data before proceeding with plotting.
"""

# Based on the box plots generated in the previous step, summarize the anomalies observed.

anomalies_summary = """
Based on the box plots of the numerical features:

1.  **Income:** The box plot for 'Income' shows a relatively symmetric distribution with some potential outliers on the higher end. These high income values are not extremely far from the main distribution but are marked as outliers by the box plot method.

2.  **Credit_Score:** The 'Credit_Score' box plot appears to have a fairly symmetric distribution with no significant outliers detected by the box plot.

3.  **Credit_Utilization:** The 'Credit_Utilization' box plot shows a distribution that is slightly skewed towards higher values. There are a few data points marked as outliers above the upper whisker.

4.  **Missed_Payments:** The box plot for 'Missed_Payments' shows a discrete distribution (as expected for counts). There are no significant outliers detected.

5.  **Loan_Balance:** The 'Loan_Balance' box plot shows a relatively symmetric distribution with a few data points marked as outliers on the higher end.

6.  **Debt_to_Income_Ratio:** The 'Debt_to_Income_Ratio' box plot appears to have a relatively symmetric distribution with no significant outliers detected.

7.  **Account_Tenure:** The 'Account_Tenure' box plot shows a relatively uniform distribution with no significant outliers detected.

**Overall Anomalies:**
The primary anomalies observed are the presence of potential outliers in 'Income', 'Credit_Utilization', and 'Loan_Balance'. These outliers are mainly on the higher end of the distributions. While not extreme in magnitude, they are flagged by the box plot visualization. The distributions of most variables appear generally well-behaved, with 'Credit_Utilization' showing a slight positive skew.

These outliers in 'Income', 'Credit_Utilization', and 'Loan_Balance' might warrant further investigation depending on the requirements of the predictive model. While some models are robust to outliers, others might be sensitive. Depending on the modeling approach, strategies like capping or transformation might be considered for these variables.
"""

print(anomalies_summary)

"""## Summarize anomalies

### Subtask:
Based on the visualizations, summarize any unexpected anomalies or data points that might require further investigation.

**Reasoning**:
Review the generated box plots and summarize the observed anomalies based on outliers and distribution shapes.

## Summary:

### Data Analysis Key Findings

*   No strong positive or negative correlations (absolute value greater than 0.5) were found between any pairs of numerical features in the dataset.
*   Most numerical features exhibited weak correlations (values between -0.1 and 0.1), suggesting little linear relationship between them.
*   Potential outliers were identified in the 'Income', 'Credit\_Utilization', and 'Loan\_Balance' variables, primarily on the higher end of their distributions, as indicated by box plots.
*   The distribution of 'Credit\_Utilization' showed a slight positive skew.
*   'Credit\_Score', 'Missed\_Payments', 'Debt\_to\_Income\_Ratio', and 'Account\_Tenure' showed distributions without significant outliers.

### Insights or Next Steps

*   Given the lack of strong linear correlations, consider exploring non-linear relationships between features if necessary for modeling.
*   Investigate the identified outliers in 'Income', 'Credit\_Utilization', and 'Loan\_Balance' to understand their origin and decide on appropriate handling methods (e.g., capping, transformation, or removal) before building predictive models, as some models can be sensitive to outliers.

# Task
Outline a predictive modeling pipeline to forecast credit delinquency, suggest 2 modeling options (simple and complex) and recommend one, explain how the model transforms customer input variables into a final risk prediction, and generate sample code or clear pseudocode for building a credit risk prediction model using relevant features.

## Outline the predictive modeling pipeline

### Subtask:
Define the key stages of a predictive modeling pipeline for credit delinquency, including data preprocessing, feature selection/engineering, model selection, training, and evaluation.

**Reasoning**:
Outline the key stages of a predictive modeling pipeline for credit delinquency based on the instructions.
"""

modeling_pipeline_stages = """
Predictive Modeling Pipeline for Credit Delinquency:

1.  **Data Collection and Understanding:**
    *   **Purpose:** Gather relevant historical customer data, including financial information, credit history, demographic details, and past payment behavior. Understand the data structure, variables, and the target variable (delinquency).

2.  **Data Preprocessing:**
    *   **Purpose:** Clean and prepare the raw data for modeling.
    *   **Steps:**
        *   **Handling Missing Values:** Address missing data points through imputation (e.g., mean, median, mode) or removal, based on the nature and extent of missingness.
        *   **Handling Outliers:** Identify and decide on a strategy for handling outliers (e.g., capping, transformation, removal) in numerical features, as they can impact model performance.
        *   **Encoding Categorical Features:** Convert categorical variables (e.g., Employment Status, Credit Card Type, Location, Month_X statuses) into a numerical format that machine learning algorithms can understand (e.g., one-hot encoding, label encoding).

3.  **Feature Engineering and Selection:**
    *   **Purpose:** Create new features from existing ones and select the most relevant features for predicting delinquency.
    *   **Steps:**
        *   **Feature Engineering:** Create potentially informative features (e.g., ratios, interaction terms, time-based features from Month_X columns).
        *   **Feature Selection:** Choose a subset of features that are most predictive of the target variable, potentially using statistical tests, correlation analysis, or feature importance from initial model runs.

4.  **Model Selection:**
    *   **Purpose:** Choose one or more appropriate machine learning algorithms for the binary classification task (delinquent or not delinquent).
    *   **Considerations:** Model complexity, interpretability, performance metrics, and computational resources.

5.  **Model Training:**
    *   **Purpose:** Train the selected model(s) using the preprocessed and feature-engineered historical data.
    *   **Steps:**
        *   Split the data into training and testing sets to evaluate the model on unseen data.
        *   Train the model on the training data, allowing the algorithm to learn the patterns associated with delinquency.

6.  **Model Evaluation:**
    *   **Purpose:** Assess the performance of the trained model using appropriate metrics.
    *   **Metrics:** Accuracy, precision, recall, F1-score, AUC-ROC curve are commonly used for classification tasks.
    *   **Techniques:** Cross-validation to ensure the model's performance is robust and not overfitting.

7.  **Model Deployment and Monitoring:**
    *   **Purpose:** Integrate the trained model into a system for making predictions on new customer data and continuously monitor its performance over time.
    *   **Steps:** Deploy the model, set up monitoring to track predictions and actual outcomes, and retrain the model periodically with new data.
"""

print(modeling_pipeline_stages)

# Define the simple modeling approach
simple_model = {
    "name": "Logistic Regression",
    "description": "A simple, linear model that estimates the probability of a binary outcome (delinquent or not delinquent). It's highly interpretable, computationally efficient, and a good baseline model.",
    "suitability": "Suitable for this problem due to its interpretability and efficiency, especially as a starting point or for scenarios where understanding feature impact is crucial. Assumes a linear relationship between features and the log-odds of the outcome."
}

# Define the complex modeling approach
complex_model = {
    "name": "Gradient Boosting Machines (e.g., LightGBM or XGBoost)",
    "description": "Ensemble methods that build multiple decision trees sequentially, with each new tree correcting the errors of the previous ones. They are known for their high predictive accuracy and ability to capture complex non-linear relationships.",
    "suitability": "Highly suitable for this problem due to their ability to handle complex patterns and interactions in the data, potentially leading to higher prediction performance compared to simpler models. Requires more tuning and is less interpretable than logistic regression."
}

# Recommend one model
recommendation = {
    "recommended_model": complex_model["name"],
    "justification": "For a credit delinquency prediction task, achieving high predictive accuracy is often a primary goal to minimize financial risk. Gradient Boosting Machines like LightGBM or XGBoost are generally known to deliver state-of-the-art performance on tabular data by capturing complex relationships that simpler models might miss. While less interpretable than Logistic Regression, their superior predictive power often outweighs this trade-off in risk assessment applications. Therefore, a complex model like Gradient Boosting is recommended for potentially better performance."
}

print("Simple Modeling Approach:")
print(f"Name: {simple_model['name']}")
print(f"Description: {simple_model['description']}")
print(f"Suitability: {simple_model['suitability']}\n")

print("Complex Modeling Approach:")
print(f"Name: {complex_model['name']}")
print(f"Description: {complex_model['description']}")
print(f"Suitability: {complex_model['suitability']}\n")

print("Recommendation:")
print(f"Recommended Model: {recommendation['recommended_model']}")
print(f"Justification: {recommendation['justification']}")



modeling_pipeline_outline = """
Predictive Modeling Pipeline for Credit Delinquency:

1.  **Data Collection and Understanding:**
    *   **Purpose:** Gather relevant historical customer data, including financial information, credit history, demographic details, and past payment behavior. Understand the data structure, variables, and the target variable (delinquency).

2.  **Data Preprocessing:**
    *   **Purpose:** Clean and prepare the raw data for modeling.
    *   **Steps:**
        *   **Handling Missing Values:** Address missing data points through imputation (e.g., mean, median, mode) or removal, based on the nature and extent of missingness.
        *   **Handling Outliers:** Identify and decide on a strategy for handling outliers (e.g., capping, transformation, removal) in numerical features, as they can impact model performance.
        *   **Encoding Categorical Features:** Convert categorical variables (e.g., Employment Status, Credit Card Type, Location, Month_X statuses) into a numerical format that machine learning algorithms can understand (e.g., one-hot encoding, label encoding).

3.  **Feature Engineering and Selection:**
    *   **Purpose:** Create new features from existing ones and select the most relevant features for predicting delinquency.
    *   **Steps:**
        *   **Feature Engineering:** Create potentially informative features (e.g., ratios, interaction terms, time-based features from Month_X columns).
        *   **Feature Selection:** Choose a subset of features that are most predictive of the target variable, potentially using statistical tests, correlation analysis, or feature importance from initial model runs.

4.  **Model Selection:**
    *   **Purpose:** Choose one or more appropriate machine learning algorithms for the binary classification task (delinquent or not delinquent).
    *   **Considerations:** Model complexity, interpretability, performance metrics, and computational resources.

5.  **Model Training:**
    *   **Purpose:** Train the selected model(s) using the preprocessed and feature-engineered historical data.
    *   **Steps:**
        *   Split the data into training and testing sets to evaluate the model on unseen data.
        *   Train the model on the training data, allowing the algorithm to learn the patterns associated with delinquency.

6.  **Model Evaluation:**
    *   **Purpose:** Assess the performance of the trained model using appropriate metrics.
    *   **Metrics:** Accuracy, precision, recall, F1-score, AUC-ROC curve are commonly used for classification tasks.
    *   **Techniques:** Cross-validation to ensure the model's performance is robust and not overfitting.

7.  **Model Deployment and Monitoring:**
    *   **Purpose:** Integrate the trained model into a system for making predictions on new customer data and continuously monitor its performance over time.
    *   **Steps:** Deploy the model, set up monitoring to track predictions and actual outcomes, and retrain the model periodically with new data.
"""

print(modeling_pipeline_outline)

"""# Task
Outline a predictive modeling pipeline to forecast credit delinquency, suggest and compare simple and complex modeling options, explain the transformation process from input to prediction, provide evaluation metrics and bias mitigation techniques, justify the chosen model, and generate sample code or pseudocode for building the model.

## Outline the predictive modeling pipeline

### Subtask:
Define the key stages of a predictive modeling pipeline for credit delinquency, including data preprocessing, feature selection/engineering, model selection, training, and evaluation.

**Reasoning**:
Outline the key stages of a predictive modeling pipeline for credit delinquency based on the instructions provided in the subtask.
"""

# Define the simple modeling approach
simple_model = {
    "name": "Logistic Regression",
    "description": "A simple, linear model that estimates the probability of a binary outcome (delinquent or not delinquent). It's highly interpretable, computationally efficient, and a good baseline model.",
    "suitability": "Suitable for this problem due to its interpretability and efficiency, especially as a starting point or for scenarios where understanding feature impact is crucial. Assumes a linear relationship between features and the log-odds of the outcome."
}

# Define the complex modeling approach
complex_model = {
    "name": "Gradient Boosting Machines (e.g., LightGBM or XGBoost)",
    "description": "Ensemble methods that build multiple decision trees sequentially, with each new tree correcting the errors of the previous ones. They are known for their high predictive accuracy and ability to capture complex non-linear relationships.",
    "suitability": "Highly suitable for this problem due to their ability to handle complex patterns and interactions in the data, potentially leading to higher prediction performance compared to simpler models. Requires more tuning and is less interpretable than logistic regression."
}

# Recommend one model
recommendation = {
    "recommended_model": complex_model["name"],
    "justification": "For a credit delinquency prediction task, achieving high predictive accuracy is often a primary goal to minimize financial risk. Gradient Boosting Machines like LightGBM or XGBoost are generally known to deliver state-of-the-art performance on tabular data by capturing complex relationships that simpler models might miss. While less interpretable than Logistic Regression, their superior predictive power often outweighs this trade-off in risk assessment applications. Therefore, a complex model like Gradient Boosting is recommended for potentially better performance."
}

print("Simple Modeling Approach:")
print(f"Name: {simple_model['name']}")
print(f"Description: {simple_model['description']}")
print(f"Suitability: {simple_model['suitability']}\n")

print("Complex Modeling Approach:")
print(f"Name: {complex_model['name']}")
print(f"Description: {complex_model['description']}")
print(f"Suitability: {complex_model['suitability']}\n")

print("Recommendation:")
print(f"Recommended Model: {recommendation['recommended_model']}")
print(f"Justification: {recommendation['justification']}")

"""## Suggest modeling options

### Subtask:
Propose two modeling approaches (simple and complex) suitable for credit delinquency prediction and recommend one based on general considerations.

"""

prediction_process_description = """
Transformation of Customer Input Variables into a Delinquency Risk Prediction:

The process of transforming raw customer input data into a credit delinquency risk prediction involves several key stages:

1.  **Data Ingestion:**
    *   Raw customer data is collected from various sources. This typically includes:
        *   **Internal Data:** Information from the financial institution's databases, such as historical transaction data, account balances, loan details, payment history (like the Month_X columns indicating payment status), and customer demographics (Age, Income, Employment Status).
        *   **External Data:** Information from credit bureaus (Credit Score, Credit Utilization, Debt-to-Income Ratio), and potentially other third-party data providers (though not explicitly shown in this dataset).
    *   This raw data is ingested into a data storage system, often in its original format, which might be structured (databases) or semi-structured (data feeds).

2.  **Feature Processing:**
    *   The raw ingested data is then processed to create the features that the predictive model will use. This stage involves several steps, often aligning with the data preprocessing and feature engineering steps outlined in the modeling pipeline:
        *   **Cleaning:** Handling missing values (as done previously by imputing Income, Credit_Score, and Loan_Balance) and addressing any inconsistencies or errors in the data.
        *   **Transformation:** Scaling numerical features (as done previously with StandardScaler) to ensure they are on a similar range, which is important for many machine learning algorithms. Other transformations, like log transformation for skewed data, might also be applied if necessary.
        *   **Encoding:** Converting categorical variables (Employment Status, Credit Card Type, Location, and the Month_X payment statuses if used as categorical features) into a numerical format. One-hot encoding is a common technique for this, creating binary columns for each category.
        *   **Feature Engineering:** Creating new, potentially more informative features from existing ones. For example, analyzing the sequence of 'Month_X' statuses to create features like the number of consecutive missed payments or the frequency of late payments over the last six months. Calculating ratios or interaction terms between existing features might also be part of this.
        *   **Feature Selection:** If necessary, selecting a subset of the processed features that are most relevant for prediction to reduce dimensionality and potentially improve model performance and interpretability.

3.  **Model Application and Prediction Output:**
    *   The cleaned and processed features for a given customer are fed into the trained predictive model.
    *   The model, based on the patterns it learned during the training phase from historical data, processes these input features.
    *   For classification models like Logistic Regression or Gradient Boosting Machines, the output is typically a **probability score** between 0 and 1, representing the likelihood of the customer being delinquent.
    *   This probability score is the **final risk prediction**. A higher score indicates a higher predicted probability of delinquency.
    *   **Interpretation and Decision-Making:** The risk score is then interpreted based on predefined thresholds. For example:
        *   Scores below a certain threshold might be classified as 'Low Risk'.
        *   Scores between two thresholds might be classified as 'Medium Risk'.
        *   Scores above a higher threshold might be classified as 'High Risk'.
    *   These risk categories or the raw risk scores are used by the financial institution for decision-making, such as approving or denying a loan application, setting interest rates, determining credit limits, or initiating proactive risk management actions for high-risk customers.
"""

print(prediction_process_description)

"""## Explain the transformation process

### Subtask:
Describe how a delinquency risk model processes customer input variables to generate a risk prediction, covering data ingestion, feature processing, and prediction output.

**Reasoning**:
Define and describe a simple and a complex modeling approach, recommend one, and print the details as requested in the instructions.

**Reasoning**:
Outline the process of transforming raw customer input into a risk prediction, detailing data ingestion, feature processing, model application, and output interpretation.
"""

model_comparison = """
Comparison of Modeling Options for Financial Risk Prediction:

1.  **Logistic Regression (Simple Model):**

    *   **Performance:**
        *   *Pros:* Good baseline performance, especially when the relationship between features and the target is approximately linear. Computationally efficient and trains quickly. Less prone to overfitting on smaller datasets compared to complex models.
        *   *Cons:* May not capture complex non-linear relationships or feature interactions effectively, potentially leading to lower predictive accuracy compared to advanced models on complex datasets.

    *   **Explainability:**
        *   *Pros:* Highly interpretable. The coefficients associated with each feature indicate the direction and magnitude of the relationship between the feature and the log-odds of delinquency. This allows for clear understanding of which factors contribute positively or negatively to risk. Regularization techniques (L1/L2) can also aid in feature selection and understanding.
        *   *Cons:* Assumes a linear relationship between features and the log-odds of the outcome, which might be an oversimplification in some real-world scenarios. Interactions between features must be explicitly engineered.

    *   **Operational Needs:**
        *   *Pros:* Fast prediction speed, making it suitable for real-time applications. Low computational requirements for training and inference. Easy to scale for large datasets. Simple to monitor as the model structure is transparent.
        *   *Cons:* Performance might degrade if complex data patterns are present and not captured through feature engineering.

    *   **Performance vs. Explainability Trade-off:**
        *   Strongly favors explainability. Offers a high degree of transparency, making it easy to understand the drivers of risk predictions, often at the cost of potentially lower predictive performance compared to more complex models.

2.  **Gradient Boosting Machines (LightGBM/XGBoost) (Complex Model):**

    *   **Performance:**
        *   *Pros:* Generally deliver state-of-the-art predictive accuracy on tabular data. Can effectively capture complex non-linear relationships and interactions between features automatically. Robust to different types of features and scaling is less critical.
        *   *Cons:* Can be prone to overfitting if not properly tuned, especially on smaller datasets. Training can be computationally intensive, although algorithms like LightGBM are optimized for speed.

    *   **Explainability:**
        *   *Pros:* While the overall model is a complex ensemble of trees, techniques like SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) can provide insights into feature importance and explain individual predictions. Built-in feature importance scores are also available.
        *   *Cons:* Less inherently interpretable than Logistic Regression. Understanding the exact path through the ensemble of trees for a single prediction is challenging. Requires additional tools and effort for post-hoc interpretability.

    *   **Operational Needs:**
        *   *Pros:* Optimized implementations (LightGBM, XGBoost) offer relatively fast prediction speeds, although typically slower than Logistic Regression. Scalable to large datasets, especially with distributed computing options. Can handle a mix of numerical and categorical features effectively.
        *   *Cons:* Model monitoring can be more complex due to the black-box nature of the ensemble. Deploying these models might require more resources compared to simpler models.

    *   **Performance vs. Explainability Trade-off:**
        *   Strongly favors performance. Designed to maximize predictive accuracy by capturing intricate patterns, often at the expense of straightforward interpretability. However, post-hoc interpretability methods are available to provide some level of explanation.

**Summary of Trade-offs:**

The choice between Logistic Regression and Gradient Boosting for financial risk prediction involves a key trade-off:

*   **Logistic Regression** is preferred when **explainability and interpretability** are paramount (e.g., regulatory requirements, needing to clearly communicate risk drivers to stakeholders) and a reasonable level of predictive performance is sufficient. Its simplicity also makes it easier to deploy and monitor.
*   **Gradient Boosting Machines** are preferred when **maximizing predictive accuracy** is the primary goal (e.g., minimizing losses from defaults) and willingness to use more complex models with post-hoc interpretability methods exists. They are powerful for capturing complex data structures but require more computational resources and effort for understanding individual predictions.
"""

print(model_comparison)

"""## Compare and contrast model options

### Subtask:
Explain the pros and cons of using different model types (e.g., logistic regression vs. decision trees or gradient boosting) for financial risk prediction, considering performance, explainability, operational needs (speed, scalability, monitoring), and how they balance performance and explainability.

**Reasoning**:
Compare the pros and cons of Logistic Regression and Gradient Boosting Machines for financial risk prediction, focusing on the requested criteria (performance, explainability, operational needs, and the performance vs. explainability trade-off).
"""

bias_mitigation_techniques = """
Techniques to Mitigate Bias in Predictive Modeling for Credit Risk:

Mitigating bias in credit risk models is crucial for fairness, regulatory compliance, and ensuring equitable access to financial services. Techniques can be applied at different stages of the modeling pipeline:

1.  **Data-Level Techniques:** These methods aim to address bias inherent in the historical data used for training.
    *   **Fairness-Aware Data Collection:** Ensure that data collection processes do not systematically disadvantage certain groups. This involves careful consideration of data sources and potential proxies for protected attributes (like race, gender, etc., though these are often not directly used due to regulations, proxies can exist).
    *   **Data Augmentation and Resampling:** If certain demographic groups are underrepresented or if the dataset reflects historical biases (e.g., discriminatory lending practices), techniques like oversampling underrepresented groups or undersampling overrepresented groups can help balance the dataset and reduce the model's tendency to favor the majority.
    *   **Fairness-Aware Data Cleaning and Preprocessing:** Identify and address biases introduced during data cleaning. For example, if missing data patterns differ significantly across groups, imputation strategies should be evaluated for their fairness impact. Outlier handling should also be assessed to ensure it doesn't disproportionately affect protected groups.
    *   **Feature Selection and Engineering with Fairness in Mind:** Carefully review features to avoid using direct or indirect proxies for protected attributes. Feature engineering should also be assessed for potential bias amplification.

2.  **In-Processing Techniques:** These methods modify the model training process or objective function to promote fairness.
    *   **Regularization with Fairness Constraints:** Add fairness-aware regularization terms to the model's objective function. These terms penalize the model if its predictions exhibit bias with respect to protected attributes, encouraging the model to find a more equitable solution during training. Examples include adversarial debiasing or using regularization terms based on fairness metrics like demographic parity or equalized odds.
    *   **Fairness-Aware Classifiers:** Use algorithms specifically designed to incorporate fairness criteria during training. These algorithms modify the learning process to reduce bias in predictions across different groups.

3.  **Post-Processing Techniques:** These methods adjust the model's predictions after training to improve fairness, without modifying the trained model itself.
    *   **Threshold Adjustment:** Adjust the decision threshold for different demographic groups to achieve fairness criteria (e.g., ensuring similar false positive rates or false negative rates across groups). This is a common and relatively simple technique, but it can sometimes reduce overall model accuracy.
    *   **Reject Option Classification:** For data points where the model's confidence is low, especially near the decision boundary and for protected groups, the model can abstain from making a prediction and instead flag the case for manual review.
    *   **Recalibration:** Adjust the predicted probabilities for different groups to align them with observed outcomes, helping to ensure that the model's confidence levels are fair across groups.

**Regulatory Considerations and Financial Applications:**

In financial risk prediction, bias mitigation is not just an ethical concern but also a regulatory requirement (e.g., Equal Credit Opportunity Act (ECOA) in the US). Techniques must be chosen carefully to:

*   **Be Defensible and Transparent:** Financial institutions need to be able to explain why their models are fair and how they mitigate bias, especially to regulators and customers.
*   **Balance Fairness and Performance:** While reducing bias is critical, models still need to be accurate to effectively manage risk. The chosen techniques should aim to achieve a reasonable balance between fairness metrics and predictive performance.
*   **Avoid Introducing New Biases:** The bias mitigation techniques themselves should be assessed to ensure they do not inadvertently introduce new forms of bias or disproportionately harm other groups.
*   **Consider Disparate Impact:** Focus on techniques that address disparate impact, where a model's seemingly neutral decision criteria lead to significantly different outcomes for protected groups.

Implementing a combination of techniques at different stages of the pipeline, along with continuous monitoring for bias, is often the most effective approach to building fair and responsible credit risk models.
"""

print(bias_mitigation_techniques)

model_justification = """
Justification for Recommending Gradient Boosting Machines for Credit Delinquency Prediction:

Based on the comparison of modeling options and the goal of minimizing financial risk through accurate predictions, Gradient Boosting Machines (such as LightGBM or XGBoost) are recommended for this credit delinquency prediction task.

**Strengths:**

1.  **High Predictive Accuracy:** Gradient Boosting models are renowned for their ability to achieve state-of-the-art accuracy on tabular datasets by capturing complex non-linear relationships and intricate feature interactions that simpler linear models like Logistic Regression might miss. In a financial risk context, higher accuracy directly translates to better risk assessment, potentially reducing losses from defaults and improving the efficiency of credit decisions.
2.  **Handles Complex Patterns:** Financial data often involves complex, non-linear relationships between various factors (income, credit history, debt levels, payment behavior, etc.) and the likelihood of delinquency. Gradient Boosting's ensemble nature and sequential learning process are well-suited to uncovering these complex patterns.
3.  **Robustness:** These models are generally robust to different scales of numerical features and can handle a mix of numerical and categorical data effectively (after appropriate encoding).

**Trade-offs:**

1.  **Lower Interpretability:** Compared to Logistic Regression, Gradient Boosting models are less inherently interpretable. Understanding the exact reason for a single prediction can be challenging due to the ensemble of numerous decision trees. This 'black-box' nature is a significant trade-off.

**Fit with Business Needs:**

1.  **Interpretability:** While not as inherently interpretable as Logistic Regression, the interpretability gap can be significantly narrowed through post-hoc techniques. Tools like SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) can be used to explain feature importance at a global level and provide local explanations for individual predictions. This is crucial for understanding the drivers of risk and communicating decisions.
2.  **Ease of Deployment and Monitoring:** Gradient Boosting models can be more computationally intensive to train and might have slightly higher latency during inference compared to Logistic Regression, potentially making deployment and real-time prediction infrastructure slightly more complex. However, optimized libraries like LightGBM and XGBoost have significantly improved efficiency. Model monitoring is also essential to detect concept drift and model performance degradation over time, which might require more sophisticated tools due to the model's complexity.
3.  **Handling Financial Data:** The ability to capture complex relationships and handle various data types makes Gradient Boosting well-suited for the nuances of financial data and credit risk factors.
4.  **Regulatory Compliance:** Regulatory bodies often require explanations for credit decisions (e.g., adverse action notices). While the direct model output is less interpretable, using post-hoc interpretability techniques is essential to meet these requirements. The institution must be able to clearly articulate the main factors contributing to a customer's risk score. This necessitates integrating interpretability tools into the modeling and decision-making process.
5.  **Transparency:** Achieving full transparency (understanding every step of the model's internal logic) is difficult with complex ensemble models. However, achieving **algorithmic transparency** (understanding how the model works at a high level) and **outcome transparency** (explaining individual predictions) is possible and necessary using the aforementioned post-hoc methods.

**Conclusion:**

Despite the trade-off in inherent interpretability, Gradient Boosting Machines are recommended due to their superior predictive power, which is a critical factor in minimizing financial risk. By effectively leveraging post-hoc interpretability techniques (like SHAP/LIME), financial institutions can gain sufficient insights into model behavior and individual predictions to meet business needs related to understanding risk drivers, regulatory compliance, and explaining decisions, thus balancing high performance with necessary interpretability and transparency requirements in a financial risk modeling context.
"""

print(model_justification)

"""## Suggest evaluation metrics

### Subtask:
Recommend a set of metrics to evaluate a financial risk prediction model, focusing on fairness, bias, and accuracy.

## Discuss bias mitigation techniques

### Subtask:
Provide examples of techniques to mitigate bias in predictive modeling for credit risk.

**Reasoning**:
List and describe techniques for mitigating bias in credit risk models, covering data, training, and post-processing stages, with a focus on financial applications.

## Justify the selected model

### Subtask:
Justify why the recommended model is appropriate for predicting delinquency, discussing its strengths, trade-offs, and how it fits business needs like interpretability, ease of deployment, handling financial data, regulatory compliance, and transparency.

**Reasoning**:
Justify the recommended model (Gradient Boosting Machines) based on its strengths, trade-offs, and fit with business needs, including interpretability, deployment, handling financial data, regulatory compliance, and transparency.
"""

import pandas as pd

# Define and describe accuracy metrics
accuracy_metrics = {
    "Accuracy": {
        "description": "The ratio of correctly predicted instances (both delinquent and non-delinquent) to the total number of instances. It provides an overall measure of correctness.",
        "suitability": "Useful as a general performance indicator, but can be misleading in imbalanced datasets (where one class is much more frequent than the other), which is common in delinquency prediction."
    },
    "Precision": {
        "description": "The ratio of true positive predictions (correctly identified delinquent accounts) to the total number of positive predictions (all instances predicted as delinquent). It measures the model's ability to avoid false positives (predicting delinquency when it doesn't occur).",
        "suitability": "Important in credit risk to avoid incorrectly denying credit to a customer who would not default (false positive), which can lead to lost business. High precision means that when the model predicts delinquency, it is very likely correct."
    },
    "Recall": {
        "description": "The ratio of true positive predictions (correctly identified delinquent accounts) to the total number of actual positive instances (all truly delinquent accounts). It measures the model's ability to find all positive instances and avoid false negatives (failing to identify a delinquent account).",
        "suitability": "Crucial in credit risk to minimize financial losses by identifying as many truly delinquent accounts as possible. High recall means that the model is good at catching delinquent customers, even if it means also flagging some non-delinquent customers (false positives)."
    },
    "F1-score": {
        "description": "The harmonic mean of Precision and Recall. It provides a single metric that balances both false positives and false negatives.",
        "suitability": "A good overall metric when there is an uneven class distribution and you need to balance the trade-off between Precision and Recall."
    },
    "AUC-ROC": {
        "description": "The Area Under the Receiver Operating Characteristic curve. The ROC curve plots the True Positive Rate (Recall) against the False Positive Rate at various threshold settings. AUC measures the model's ability to distinguish between the positive and negative classes across all possible thresholds.",
        "suitability": "Provides a comprehensive measure of the model's discriminatory power, independent of the classification threshold. A higher AUC indicates better overall performance in ranking positive and negative instances."
    }
}

# Define and describe fairness/bias metrics
fairness_metrics = {
    "Demographic Parity (Statistical Parity)": {
        "description": "Measures if the proportion of positive predictions (predicted as delinquent) is the same across different demographic groups (e.g., different age groups, locations). It assesses if the model's positive prediction rate is independent of the protected attribute.",
        "importance": "Important to ensure that the model does not disproportionately flag individuals from certain protected groups as delinquent, which could lead to discriminatory practices in credit approval or terms, regardless of their actual risk."
    },
    "Equalized Odds": {
        "description": "Requires that the True Positive Rate (Recall) and False Positive Rate are the same across different demographic groups. This means the model should perform equally well in identifying truly delinquent individuals and in incorrectly flagging non-delinquent individuals, regardless of their group.",
        "importance": "Crucial in credit risk to ensure that the model's errors (both false positives and false negatives) are distributed fairly across different groups. This prevents situations where, for example, one group has a much higher rate of being falsely denied credit while another group has a much higher rate of being falsely approved."
    },
     "Predictive Parity (Positive Predictive Value Parity)": {
        "description": "Requires that the Precision (the proportion of true positives among those predicted positive) is the same across different demographic groups. This means that when the model predicts delinquency for individuals in different groups, the probability of that prediction being correct should be the same.",
        "importance": "Relevant for ensuring that the 'cost' of a positive prediction (e.g., being subject to higher scrutiny or denial of credit) is similarly justified across different groups. It addresses whether the model's positive predictions are equally reliable for all groups."
    }
}

# Explain the need for both accuracy and fairness metrics
comprehensive_evaluation_explanation = """
Why both Accuracy and Fairness Metrics are Necessary for Financial Risk Models:

Evaluating a financial risk model solely on traditional accuracy metrics like Accuracy or AUC can be insufficient and potentially misleading, especially in sensitive applications like credit risk. While accuracy metrics tell us how well the model performs overall and in identifying delinquent vs. non-delinquent accounts, they do not reveal whether the model's performance is equitable across different groups of people.

Financial risk models, particularly in credit, can have a significant impact on individuals' lives and opportunities. If a model exhibits bias against certain demographic groups, it can perpetuate or even amplify existing societal inequalities, leading to unfair outcomes such as discriminatory lending practices.

Fairness metrics are essential for detecting and quantifying such biases. By examining metrics like Demographic Parity and Equalized Odds, we can assess whether the model's predictions or error rates are disproportionately affecting protected groups.

Therefore, a comprehensive evaluation of a financial risk model requires considering both:

1.  **Accuracy Metrics:** To understand the overall predictive performance and the model's ability to correctly identify risk levels.
2.  **Fairness Metrics:** To ensure that the model's predictions are equitable across different segments of the population and do not lead to unfair or discriminatory outcomes.

Balancing these two sets of metrics is critical for building responsible and ethical AI systems in finance that are both accurate and fair. Regulatory bodies increasingly emphasize fairness and non-discrimination in algorithmic decision-making, making the evaluation of bias a mandatory part of the model development and monitoring lifecycle.
"""

print("Accuracy Metrics:")
for metric, details in accuracy_metrics.items():
    print(f"- **{metric}:** {details['description']} Suitability: {details['suitability']}")

print("\nFairness and Bias Metrics:")
for metric, details in fairness_metrics.items():
    print(f"- **{metric}:** {details['description']} Importance: {details['importance']}")

print("\n" + comprehensive_evaluation_explanation)

"""## Suggest evaluation metrics

### Subtask:
Recommend a set of metrics to evaluate a financial risk prediction model, focusing on fairness, bias, and accuracy.

**Reasoning**:
Define and describe relevant evaluation metrics for accuracy, fairness, and bias in the context of credit risk prediction.

## Generate sample code/pseudocode

### Subtask:
Provide sample code or pseudocode for building a credit risk prediction model, using relevant features.

**Reasoning**:
Define features, split data, create preprocessing and model pipelines, train the model, make predictions, and print the missing values after imputation and the head of the dataframe to confirm the data is ready for modeling.
"""



import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import lightgbm as lgb
from sklearn.metrics import classification_report, roc_auc_score

# Assuming 'data' DataFrame is already loaded and missing values are handled

# Define features (X) and target (y)
# Exclude 'Customer_ID' as it's just an identifier
X = data.drop(['Customer_ID', 'Delinquent_Account'], axis=1)
y = data['Delinquent_Account']

# Identify categorical and numerical features
categorical_features = X.select_dtypes(include=['object']).columns
numerical_features = X.select_dtypes(include=np.number).columns

# Create preprocessing pipelines for numerical and categorical features
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Create a column transformer to apply different transformations to different columns
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Create the full modeling pipeline with preprocessing and the LightGBM model
model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                               ('classifier', lgb.LGBMClassifier(random_state=42))])

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train the model
model_pipeline.fit(X_train, y_train)

# Make predictions
y_pred = model_pipeline.predict(X_test)
y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1] # Get probabilities for AUC

# Evaluate the model
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("\nAUC-ROC Score:", roc_auc_score(y_test, y_pred_proba))

print("\nSample Predictions:")
sample_predictions = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Predicted_proba': y_pred_proba}).head()
display(sample_predictions)

"""Here is sample code demonstrating how to build a credit risk prediction model using a Gradient Boosting Classifier (LightGBM) as recommended earlier. This code includes steps for data preparation, model training, and making predictions."""